{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *An Introduction to*\n",
    "# Natural Language Processing\n",
    "\n",
    "#### Contributors\n",
    "Helene Willits,\n",
    "Shaina Bagri,\n",
    "Rachel Castellino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Language Syntax and Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic History of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Understanding\n",
    "\n",
    "Natural language understanding is the process that predicts meaning from processed text. \n",
    "\n",
    "#### How do we get Computers to Understand Words?\n",
    "Computers are not very good at understanding words. However, they are built to understand numbers. In order to create complex relationships between words, Natural Language Understanding represents words using number vectors that make it easy to build and analyze the relationships between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Natural Language Generation (NLG)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language generation is a process that transforms structured data into human-readable English text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stages of NLG Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of ways to break down the NLG process into different stages, but the following are more common. These stages help provide a step-by-step understanding behind the concept of natural language generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, data typically contains much more information than is needed to generate the document, so it is important to establish limits for the content to determine which data is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the analyzed data needs to be interpreted and put into context. This typically happens through machine learning techniques which recognize patterns in the processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data is interpreted, it needs to be organized in order to create a narrative structure and a document plan. This typically results in a general document structure or template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage is also typically referred to as microplanning. It involves choosing expressions and words within each sentence and combining sentences together based on their relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grammaticalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the sentences have been clustered, the process needs to make sure that they follow correct grammar, spelling, and punctuation. Additionally, they need to follow syntax, morphology, and orthography rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the data is input into the previously generated templates and the formatting of the document is checked to make sure it is done correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Approaches to NLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two major approaches to NLG are using templates and creating documents dynamically. The following approaches show examples of these and how the approaches have built on themselves over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Gap-Filling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple gap-filling approach is one of the oldest approaches. It uses a template system in order to generate texts. This works best for texts that have a predefined structure and simply need a small amount of data to be filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripts or Rules-Producing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above approach was expanded by incorporating general-purpose programming constructs through either a scripting language or business rules. The scripting approach embeds a template within a general-purpose scripting language. An example of this is using web templating languages. The business rule approaches are similar to the scripting approach but focus on writing business rules rather than scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word-Level Grammatical Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scripts or rules-producing text approach was further developed by adding word-level grammatical functions to handle morphology, morphophonology, and orthography rules as well as their exceptions. This ensures the template systems are more complete making it easier for them to generate texts that are grammatically correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Sentence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach exemplifies the transition from templates to dynamically created documents. It builds on the previous approach by using representations of the desired linguistic structure or the intended meaning to dynamically create sentences. Additionally, the system can linguistically \"optimize\" sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Document Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic document creation, then, uses the generated sentences to create a document. The document generated and the process for generating it depend on the goal of the text. For example, persuasive texts would be organized differently than informative ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for Implementing NLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variety of models have been used to implement NLG, and the progression through them can be seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Chain was one of the first algorithms used to implement NLG. It uses the current word and considers the relationships between it and every other unique word in order to predict what the next word in the sentence will be. A common example of this is when smartphones generate suggested next words while you are typing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Markov Chain only uses the immediately previous word to predict the next word, RNN use all of the previous words they encounter in order to predict the next word. This memory allows the RNN to \"remember\" the background and context of the text, making them more effective to generate language. They do this by iterating through a feedforward network that calculates the probability of the next word and stores the word with the highest probability in memory. However, RNNs cannot store words encountered remotely in longer sequences and thus ends up making predictions based on only the most recent word. As such, they have difficulty generating coherent long sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of NLP Today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/sciforce/a-comprehensive-guide-to-natural-language-generation-dd63a4b6e548\n",
    "\n",
    "https://research.aimultiple.com/nlg/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
