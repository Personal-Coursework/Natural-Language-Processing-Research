{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *An Introduction to*\n",
    "# Natural Language Processing\n",
    "\n",
    "#### Contributors\n",
    "Helene Willits\n",
    "Shaina Bagri\n",
    "Rachel Castellino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Language Syntax and Semantics\n",
    "\n",
    "There are various language semantics theories that compete in the world of Natural Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic History of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "\n",
    "Natural Language Processing is the process of adding structure to raw text so that it can be understood and analyzed by computers. This mainly consists of defining the properties of the text so that the computer can determine the importance of different words and the relationships between them.\n",
    "\n",
    "### How do we get Computers to Understand Words?\n",
    "Computers are not very good at understanding words. However, they are built to understand numbers. In order to create complex relationships between words, NLP represents words using number vectors that make it easy to build and analyze the relationships between words.\n",
    "\n",
    "### Preprocessing\n",
    "We begin creating our NLP model by preprocessing the data. This step helps us to remove any noise in the data and reduce the ambiguity of our resulting model. There are many ways that Engineers do this, but here are some of the most common ones:\n",
    "\n",
    "##### Splitting\n",
    "The raw text is split into sections so that important sections can be more easily identified.\n",
    "\n",
    "##### Deduplication\n",
    "Similar sections of the text are grouped to remove redundancy and start forming relationships.\n",
    "\n",
    "##### Normalization\n",
    "Data that is not standard is clarified.\n",
    "\n",
    "##### Stratification\n",
    "Important parts of the text are selected to be focused on when performing the upcoming analysis.\n",
    "\n",
    "### Parsing\n",
    "The next step in our language processing is to parse the data. This means separating the data into various elements such as words, punctuation, phrases, and more.\n",
    "\n",
    "##### Tokenization\n",
    "Words and sentences are identified so that they can be processed.\n",
    "\n",
    "##### Part-of-Speech Tagging\n",
    "Words are classified based on their grammatical rules, giving them tags as Nouns, Verbs, Adjectives, and more.\n",
    "\n",
    "##### Stemming / Lemmatization\n",
    "Words are connected back to their root, so that verbs like *wanting*, *wanted*, and *wants* are all mapped back to the root *want*.\n",
    "\n",
    "##### Dependency Parsing\n",
    "Relationships between words within a sentence are identified. This is done by applying deep learning algorithms. For example, in the sentence \"I love my fluffy dog,\" Dependency Parsing would identify that the adjective \"fluffy\" is meant to describe the noun \"dog\" and that the verb \"love\" refers to the noun \"dog,\" but would know that there isn't an obvious relationship between the words \"love\" and \"fluffy.\" \n",
    "\n",
    "##### Clause Analysis\n",
    "Identifies clauses within a sentence. This process requires both supervised machine learning and linguistic rules in order to separate sentences into blocks.\n",
    "\n",
    "### Analyzing\n",
    "Now we are ready to analyze our data to find relationships between topics and trends within the data. In this step, we discover more about the text as a whole. There are various methods of analysis that are commonly used:\n",
    "\n",
    "##### Singular Value Decomposition\n",
    "The frequency of each word in the document is recorded in a matrix so that the model can determine the importance of the topics mentioned.\n",
    "\n",
    "##### Latent Dirichlet Allocation\n",
    "\n",
    "##### Categorization\n",
    "Similar pieces of text are grouped together into categories using supervised machine learning or by following a pre-made set of categorization rules.\n",
    "\n",
    "##### Sentiment\n",
    "The text is categorized by sentiment, often into buckets such as positive, negative, and neutral sentiment.\n",
    "\n",
    "##### Word Embedding\n",
    "Uses a spacial model to plot words so that words that are used in similar ways are closer together.\n",
    "\n",
    "As you can see, Natural Language Processing gives Engineers a variety of ways to define, categorize, and relate data from our text. At this point, we have created semi-structured data. Now that we know what was expressed, we can develop a model that understands the underlying meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Understanding\n",
    "Natural Language Understanding is the process that predicts the meaning of processed text. Engineers determine the intent of a message using the document's context and various methods of reducing ambiguity. This is a harder task than Natural Language Generation because of the unpredictable nature of the input text.\n",
    "\n",
    "### Extracting Information\n",
    "\n",
    "##### Noun Groups\n",
    "Identifies which noun in a sentence is the subject and uses context to determine the meaning of that subject.\n",
    "\n",
    "##### Entity Detection\n",
    "Identifies nouns as names of people, groups, places, and more in order to better understand their relationships with other words.\n",
    "\n",
    "##### Sentiment Analysis\n",
    "This version of sentiment analysis identifies the sentiment of a statement and determines its relationship with the entities in the text.\n",
    "\n",
    "##### Semantic Role Labeling\n",
    "Now that the words have been individually categorized, we can develop relationships between them with Semantic Role Labeling. For each verb, the model identifies:\n",
    "- the entity that performs the action\n",
    "- the entity that receives the action\n",
    "as well as some more roles if they apply to the verb, such as:\n",
    "- beneficiaries of the action\n",
    "This allows \n",
    "\n",
    "##### Topic Classification\n",
    "\n",
    "### Interpreting Information\n",
    "\n",
    "<!-- ##### Rule Generation\n",
    "Creates entity recognition rules using supervised machine learning.\n",
    "\n",
    "##### Text Summarization\n",
    "Identifies important information within the text and summarizes it.  -->\n",
    "\n",
    "### Graph-Based Parsing\n",
    "Graph based parsing is a traditional method of message interpretation in NLU.\n",
    "\n",
    "Using the elements of word identification that we developed so far, important concepts in the text are identified and represented as nodes. These nodes are then structured into a directed graph with edges between every node. Engineers then use algorithmic approaches to determine the relationships between nodes that represent syntactic, semantic, and topic relationships in order to predict which relationships are important.\n",
    "\n",
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Natural Language Generation (NLG)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language generation is a process that transforms structured data into human-readable English text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stages of NLG Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to pick either Medium or AI Multiple Research...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Approaches to NLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two major approaches to NLG are using templates and creating documents dynamically. The following approaches show examples of these and how the approaches have built on themselves over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Gap-Filling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple gap-filling approach is one of the oldest approaches. It uses a template system in order to generate texts. This works best for texts that have a predefined structure and simply need a small amount of data to be filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripts or Rules-Producing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word-Level Grammatical Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Sentence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Document Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for Implementing NLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it may seem like Natural Language Processing can do just about anything, NLP models are much more restricted than many people realize. NLP models are trained to perform extremely specific tasks. Even within the scope of the tasks that they are designed to perform, NLP models can have huge amounts of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Implications\n",
    "\n",
    "Even with these innate limitations, there are limits to what Natural Language Processing should be used for. NLP systems are used widely in everyday life and have an enormous effect on people's interactions with each other, technology, and the services that are available to them. Because of this, it is critical that those who are using NLP consider the implications of the work they do on the world at large and the individuals who are affected by it. \n",
    "\n",
    "Some of the most critical concerns regarding NLP at the moment are related to its ability to create or propegate discrimination against certain groups of people. With careful ethical consideration, NLP can be used in ways that minimize discrimination and increase equal access for all people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of NLP Today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
